best_Pars = fit_caret_penalized$bestTune
print(min(fit_caret_penalized$results$RMSE))
best_Model <- glmnet(trainx, trainy, alpha = best_Pars$alpha,lambda=lambdalist)
# best type must be a penalized regression model
allbestPars[[j]] = best_Pars
# only considering penalized regression models, so specified the same
lambda.out = best_Pars$lambda
alpha.out = best_Pars$alpha
allpredictedCV[groupj]  = predict(best_Model,newx=validx,s=lambda.out)
}
R2.assess = 1 - sum((allpredictedCV-y)^2)/sum((y-mean(y))^2); R2.assess
input = read.csv("Heart_Disease_Cleveland.csv")
names(input)
heart = input[,c(1,4,5,8,10)]
heart$HD = rep(0, length(input$DiseaseStatus))
heart$HD[which(input$DiseaseStatus > 0)] = 1
heart$HD = factor(heart$HD)
# read in libraries
library(MASS)
input = read.csv("Heart_Disease_Cleveland.csv")
names(input)
heart = input[,c(1,4,5,8,10)]
heart$HD = rep(0, length(input$DiseaseStatus))
heart$HD[which(input$DiseaseStatus > 0)] = 1
heart$HD = factor(heart$HD)
# read in libraries
library(MASS)
View(heart)
View(heart)
set.seed(8)
xy.in = trainxy.out  # calling the outer-training set to be fed into the inner CV, for use in model selection
set.seed(8)
library(MASS)
##############################
##entire model-fitting process##
xy.in = heart
n.in = dim(xy.in)[1]
k.in = 10
groups.in = rep(1:k.in,length=n.in)
cvgroups.in = sample(groups.in,n.in)
# with model selection
allpredictedcv10 = matrix(,ncol=6,nrow=n.in)
for (i in 1:k.in) {
# split out the test set
newdata.in = xy.in[cvgroups.in==i,]
#fit LDA on 2 predictors, for training set (cvgroups.in!=i)
lda2fit = lda(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,1] = predict(lda2fit,newdata.in)$class
#fit LDA on 5 predictors, for training set (cvgroups.in!=i)
lda5fit = lda(HD ~., data= xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,2] = predict(lda5fit,newdata.in)$class
#fit QDA on 2 predictors, for training set (cvgroups.in!=i)
qda2fit = qda(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,3] = predict(qda2fit,newdata.in)$class
#fit QDA on 5 predictors, for training set (cvgroups.in!=i)
qda5fit = qda(HD ~., data= xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,4] = predict(qda5fit,newdata.in)$class
#fit logistic on 2 predictors, for training set (cvgroups.in!=i)
log2fit = glm(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i), family=binomial)
log2prob = predict(log2fit,newdata.in,type="response")
log2fact = rep(1,dim(newdata.in)[1]); log2fact[log2prob > 0.5] = 2
allpredictedcv10[cvgroups.in==i,5] = log2fact
#fit logistic on 5 predictors, for training set (cvgroups.in!=i)
log5fit = glm(HD ~., data= xy.in, subset=(cvgroups.in!=i),family=binomial)
log5prob = predict(log5fit,newdata.in,type="response")
log5fact = rep(1,dim(newdata.in)[1]); log5fact[log5prob > 0.5] = 2
allpredictedcv10[cvgroups.in==i,6] = log5fact
}
#relabel as original values, not factor levels
allpredictedcv10 = allpredictedcv10-1  # now a table of predicted 0-1 values for HD
#compute the CV values
allcv10 = rep(0,6)
for (m in 1:6) allcv10[m] = sum(xy.in$HD!=allpredictedcv10[,m])/n.in
bestmodels = (1:6)[allcv10 == min(allcv10)]
##############################
##############################
bestmodels
a <- for (m in 1:6) allcv10[m] = sum(xy.in$HD!=allpredictedcv10[,m])/n.in
a
allcv10
#Purpose of double cross-validation:
# assessment - what proportion of the cross-validated classifications (valid predictions of
# new observations, based on model selected using the entire model-selection process)
# match the actual observations?
table(heart$HD,allpredictedCV.out)
##############################################################
#Purpose of double cross-validation:
# assessment - what proportion of the cross-validated classifications (valid predictions of
# new observations, based on model selected using the entire model-selection process)
# match the actual observations?
table(heart$HD,allpredictedCV.out)
##### model assessment OUTER shell #####
nvalid = 100
xy.out = heart
n.out = dim(xy.out)[1]
#define the validation set
set.seed(8)
validset = sample(1:n.out,nvalid)
trainxy.out = xy.out[-validset,]
testxy.out = xy.out[validset,]
xy.out = heart
n.out = dim(xy.out)[1]
#define the cross-validation splits
k.out = 10
groups.out = rep(1:k.out,length=n.out)  #produces list of group labels
set.seed(8)
cvgroups.out = sample(groups.out,n.out)  #orders randomly, with seed (8)
allpredictedCV.out = rep(NA,n.out)
### model assessment OUTER shell ###
for (j in 1:k.out)  {  #be careful not to re-use loop indices
groupj.out = (cvgroups.out == j)
# define the training set for outer loop
trainxy.out = xy.out[!groupj.out,]
#define the validation set for outer loop
testxy.out = xy.out[groupj.out,]
testx2.out <- testxy.out %>% select(MaxHeartRate, STdepress)
testx5.out <- testxy.out %>% select(-HD)
ModelList = list(HD ~ MaxHeartRate + STdepress,HD ~.)
#  set.seed(8)
training = trainControl(method = "cv", number = 10)
##############################################
###   model selection on trainxy.out       ###
##############################################
# cross-validation of LDA model two predictors
fit_caret_LDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of LDA model full
fit_caret_LDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of QDA model two predictors
fit_caret_QDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of QDA model full
fit_caret_QDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of logistic model two predictors
fit_caret_logistic2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
# cross-validation of logistic model full
fit_caret_logistic5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
############# identify selected model to fit to full data #############
# all best models
all_Accuracy = c(fit_caret_LDA2$results$Accuracy,
fit_caret_LDA5$results$Accuracy,
fit_caret_QDA2$results$Accuracy,
fit_caret_QDA5$results$Accuracy,
fit_caret_logistic2$results$Accuracy,
fit_caret_logistic5$results$Accuracy)
all_Error = 1-all_Accuracy
bestmodels = (1:6)[all_Error == min(all_Error)]
bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
print(all_Error)
print(paste("Best model at outer loop",j,"is",bestmodel))
##############################################
###   resulting in bestmodels              ###
##############################################
#relabel as original values, not factor levels
if (bestmodel == 1)   predictvalid = as.numeric(predict(fit_caret_LDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 2)   predictvalid = as.numeric(predict(fit_caret_LDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 3)   predictvalid = as.numeric(predict(fit_caret_QDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 4)   predictvalid = as.numeric(predict(fit_caret_QDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 5)   predictvalid = as.numeric(predict(fit_caret_logistic2$finalModel, newdata = testx2.out, type = "response")>0.5)
if (bestmodel == 6)   predictvalid = as.numeric(predict(fit_caret_logistic5$finalModel, newdata = testx5.out, type = "response")>0.5)
#print(length(predictvalid))
allpredictedCV.out[groupj.out] = predictvalid
print(Sys.time())
}
bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
# take the single selected best model and fit to the validation set
if (bestmodel == 1)  {
lda2fit.train = lda(HD ~ MaxHeartRate + STdepress, data=trainxy.out)
predictvalid = as.numeric(predict(lda2fit.train, testxy.out)$class)
}
if (bestmodel == 2)  {
lda5fit.train = lda(HD ~ ., data=trainxy.out)
predictvalid = as.numeric(predict(lda5fit.train, testxy.out)$class)
}
if (bestmodel == 3)  {
qda2fit.train = qda(HD ~ MaxHeartRate + STdepress, data=trainxy.out)
predictvalid = as.numeric(predict(qda2fit.train, testxy.out)$class)
}
if (bestmodel == 4)  {
qda5fit.train = qda(HD ~ ., data=trainxy.out)
predictvalid = as.numeric(predict(qda5fit.train, testxy.out)$class)
}
if (bestmodel == 5)  {
log2fit.train = glm(HD ~ MaxHeartRate + STdepress, data= trainxy.out, family=binomial)
log2prob.test = predict(log2fit.train,testxy.out,type="response")
predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[log2prob.test > 0.5] = 2
}
if (bestmodel == 6)  {
log5fit.train = glm(HD ~ ., data= trainxy.out, family=binomial)
log5prob.test = predict(log5fit.train,testxy.out,type="response")
predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[log5prob.test > 0.5] = 2
}
#relabel as original values, not factor levels
predictvalid = predictvalid-1  # now a vector of predicted 0-1 values for HD in validation set
#assessment
CV.valid = sum(testxy.out$HD!=predictvalid)/nvalid
p.valid = 1-CV.valid
p.valid
# define data frame heart as in WebWork Lesson 8, Problem 4
input = read.csv("Heart_Disease_Cleveland.csv")
names(input)
heart = input[,c(1,4,5,8,10)]
heart$HD = rep(0, length(input$DiseaseStatus))
heart$HD[which(input$DiseaseStatus > 0)] = 1
heart$HD = factor(heart$HD)
# read in libraries
library(MASS)
###################### More consistent way (with caret) ######################
library(caret)
library(dplyr)
##### model assessment OUTER 10-fold CV (with model selection INNER 10-fold CV as part of model-fitting) #####
xy.out = heart
n.out = dim(xy.out)[1]
#define the cross-validation splits
k.out = 10
groups.out = rep(1:k.out,length=n.out)  #produces list of group labels
set.seed(8)
cvgroups.out = sample(groups.out,n.out)  #orders randomly, with seed (8)
allpredictedCV.out = rep(NA,n.out)
### model assessment OUTER shell ###
for (j in 1:k.out)  {  #be careful not to re-use loop indices
groupj.out = (cvgroups.out == j)
# define the training set for outer loop
trainxy.out = xy.out[!groupj.out,]
#define the validation set for outer loop
testxy.out = xy.out[groupj.out,]
testx2.out <- testxy.out %>% select(MaxHeartRate, STdepress)
testx5.out <- testxy.out %>% select(-HD)
ModelList = list(HD ~ MaxHeartRate + STdepress,HD ~.)
#  set.seed(8)
training = trainControl(method = "cv", number = 10)
##############################################
###   model selection on trainxy.out       ###
##############################################
# cross-validation of LDA model two predictors
fit_caret_LDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of LDA model full
fit_caret_LDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of QDA model two predictors
fit_caret_QDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of QDA model full
fit_caret_QDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of logistic model two predictors
fit_caret_logistic2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
# cross-validation of logistic model full
fit_caret_logistic5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
############# identify selected model to fit to full data #############
# all best models
all_Accuracy = c(fit_caret_LDA2$results$Accuracy,
fit_caret_LDA5$results$Accuracy,
fit_caret_QDA2$results$Accuracy,
fit_caret_QDA5$results$Accuracy,
fit_caret_logistic2$results$Accuracy,
fit_caret_logistic5$results$Accuracy)
all_Error = 1-all_Accuracy
bestmodels = (1:6)[all_Error == min(all_Error)]
bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
print(all_Error)
print(paste("Best model at outer loop",j,"is",bestmodel))
##############################################
###   resulting in bestmodels              ###
##############################################
#relabel as original values, not factor levels
if (bestmodel == 1)   predictvalid = as.numeric(predict(fit_caret_LDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 2)   predictvalid = as.numeric(predict(fit_caret_LDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 3)   predictvalid = as.numeric(predict(fit_caret_QDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 4)   predictvalid = as.numeric(predict(fit_caret_QDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 5)   predictvalid = as.numeric(predict(fit_caret_logistic2$finalModel, newdata = testx2.out, type = "response")>0.5)
if (bestmodel == 6)   predictvalid = as.numeric(predict(fit_caret_logistic5$finalModel, newdata = testx5.out, type = "response")>0.5)
#print(length(predictvalid))
allpredictedCV.out[groupj.out] = predictvalid
print(Sys.time())
}
##############################################################
#Purpose of double cross-validation:
# assessment - what proportion of the cross-validated classifications (valid predictions of
# new observations, based on model selected using the entire model-selection process)
# match the actual observations?
table(heart$HD,allpredictedCV.out)
CV10.out = sum(heart$HD!=allpredictedCV.out)/n.out
p.out = 1-CV10.out; p.out
p.valid
# define data frame heart as in WebWork Lesson 8, Problem 4
input = read.csv("Heart_Disease_Cleveland.csv")
names(input)
heart = input[,c(1,4,5,8,10)]
heart$HD = rep(0, length(input$DiseaseStatus))
heart$HD[which(input$DiseaseStatus > 0)] = 1
heart$HD = factor(heart$HD)
# read in libraries
library(MASS)
###################### More consistent way (with caret) ######################
library(caret)
library(dplyr)
##### model assessment OUTER 10-fold CV (with model selection INNER 10-fold CV as part of model-fitting) #####
xy.out = heart
n.out = dim(xy.out)[1]
#define the cross-validation splits
k.out = 10
groups.out = rep(1:k.out,length=n.out)  #produces list of group labels
set.seed(8)
cvgroups.out = sample(groups.out,n.out)  #orders randomly, with seed (8)
allpredictedCV.out = rep(NA,n.out)
### model assessment OUTER shell ###
for (j in 1:k.out)  {  #be careful not to re-use loop indices
groupj.out = (cvgroups.out == j)
# define the training set for outer loop
trainxy.out = xy.out[!groupj.out,]
#define the validation set for outer loop
testxy.out = xy.out[groupj.out,]
testx2.out <- testxy.out %>% select(MaxHeartRate, STdepress)
testx5.out <- testxy.out %>% select(-HD)
ModelList = list(HD ~ MaxHeartRate + STdepress,HD ~.)
#  set.seed(8)
training = trainControl(method = "cv", number = 10)
##############################################
###   model selection on trainxy.out       ###
##############################################
# cross-validation of LDA model two predictors
fit_caret_LDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of LDA model full
fit_caret_LDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "lda",
trControl = training)
# cross-validation of QDA model two predictors
fit_caret_QDA2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of QDA model full
fit_caret_QDA5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "qda",
trControl = training)
# cross-validation of logistic model two predictors
fit_caret_logistic2 = train(ModelList[[1]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
# cross-validation of logistic model full
fit_caret_logistic5 = train(ModelList[[2]],
data = trainxy.out,   # important, only run caret on training data from split in out loop
method = "glm",
trControl = training)
############# identify selected model to fit to full data #############
# all best models
all_Accuracy = c(fit_caret_LDA2$results$Accuracy,
fit_caret_LDA5$results$Accuracy,
fit_caret_QDA2$results$Accuracy,
fit_caret_QDA5$results$Accuracy,
fit_caret_logistic2$results$Accuracy,
fit_caret_logistic5$results$Accuracy)
all_Error = 1-all_Accuracy
bestmodels = (1:6)[all_Error == min(all_Error)]
bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
print(all_Error)
print(paste("Best model at outer loop",j,"is",bestmodel))
##############################################
###   resulting in bestmodels              ###
##############################################
#relabel as original values, not factor levels
if (bestmodel == 1)   predictvalid = as.numeric(predict(fit_caret_LDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 2)   predictvalid = as.numeric(predict(fit_caret_LDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 3)   predictvalid = as.numeric(predict(fit_caret_QDA2$finalModel, newdata = testx2.out)$class)-1
if (bestmodel == 4)   predictvalid = as.numeric(predict(fit_caret_QDA5$finalModel, newdata = testx5.out)$class)-1
if (bestmodel == 5)   predictvalid = as.numeric(predict(fit_caret_logistic2$finalModel, newdata = testx2.out, type = "response")>0.5)
if (bestmodel == 6)   predictvalid = as.numeric(predict(fit_caret_logistic5$finalModel, newdata = testx5.out, type = "response")>0.5)
#print(length(predictvalid))
allpredictedCV.out[groupj.out] = predictvalid
print(Sys.time())
}
#Purpose of double cross-validation:
# assessment - what proportion of the cross-validated classifications (valid predictions of
# new observations, based on model selected using the entire model-selection process)
# match the actual observations?
table(heart$HD,allpredictedCV.out)
CV10.out = sum(heart$HD!=allpredictedCV.out)/n.out
p.out = 1-CV10.out; p.out
CV.valid = sum(testxy.out$HD!=predictvalid)/nvalid
p.valid = 1-CV.valid
p.valid
##### model assessment OUTER shell #####
nvalid = 100
xy.out = heart
n.out = dim(xy.out)[1]
#define the validation set
set.seed(8)
validset = sample(1:n.out,nvalid)
trainxy.out = xy.out[-validset,]
testxy.out = xy.out[validset,]
##############################
##entire model-fitting process##
xy.in = train.out
##### model assessment OUTER shell #####
nvalid = 100
xy.out = heart
n.out = dim(xy.out)[1]
#define the validation set
set.seed(8)
validset = sample(1:n.out,nvalid)
trainxy.out = xy.out[-validset,]
testxy.out = xy.out[validset,]
##############################
##entire model-fitting process##
xy.in = trainxy.out
n.in = dim(xy.in)[1]
k.in = 10
groups.in = rep(1:k.in,length=n.in)
cvgroups.in = sample(groups.in,n.in)
# with model selection
allpredictedcv10 = matrix(,ncol=6,nrow=n.in)
for (i in 1:k.in) {
# split out the test set
newdata.in = xy.in[cvgroups.in==i,]
#fit LDA on 2 predictors, for training set (cvgroups.in!=i)
lda2fit = lda(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,1] = predict(lda2fit,newdata.in)$class
#fit LDA on 5 predictors, for training set (cvgroups.in!=i)
lda5fit = lda(HD ~., data= xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,2] = predict(lda5fit,newdata.in)$class
#fit QDA on 2 predictors, for training set (cvgroups.in!=i)
qda2fit = qda(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,3] = predict(qda2fit,newdata.in)$class
#fit QDA on 5 predictors, for training set (cvgroups.in!=i)
qda5fit = qda(HD ~., data= xy.in, subset=(cvgroups.in!=i))
allpredictedcv10[cvgroups.in==i,4] = predict(qda5fit,newdata.in)$class
#fit logistic on 2 predictors, for training set (cvgroups.in!=i)
log2fit = glm(HD ~ MaxHeartRate + STdepress, data=xy.in, subset=(cvgroups.in!=i), family=binomial)
log2prob = predict(log2fit,newdata.in,type="response")
log2fact = rep(1,dim(newdata.in)[1]); log2fact[log2prob > 0.5] = 2
allpredictedcv10[cvgroups.in==i,5] = log2fact
#fit logistic on 5 predictors, for training set (cvgroups.in!=i)
log5fit = glm(HD ~., data= xy.in, subset=(cvgroups.in!=i),family=binomial)
log5prob = predict(log5fit,newdata.in,type="response")
log5fact = rep(1,dim(newdata.in)[1]); log5fact[log5prob > 0.5] = 2
allpredictedcv10[cvgroups.in==i,6] = log5fact
}
bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
# take the single selected best model and fit to the validation set
if (bestmodel == 1)  {
lda2fit.train = lda(HD ~ MaxHeartRate + STdepress, data=trainxy.out)
predictvalid = as.numeric(predict(lda2fit.train, testxy.out)$class)
}
if (bestmodel == 2)  {
lda5fit.train = lda(HD ~ ., data=trainxy.out)
predictvalid = as.numeric(predict(lda5fit.train, testxy.out)$class)
}
if (bestmodel == 3)  {
qda2fit.train = qda(HD ~ MaxHeartRate + STdepress, data=trainxy.out)
predictvalid = as.numeric(predict(qda2fit.train, testxy.out)$class)
}
if (bestmodel == 4)  {
qda5fit.train = qda(HD ~ ., data=trainxy.out)
predictvalid = as.numeric(predict(qda5fit.train, testxy.out)$class)
}
if (bestmodel == 5)  {
log2fit.train = glm(HD ~ MaxHeartRate + STdepress, data= trainxy.out, family=binomial)
log2prob.test = predict(log2fit.train,testxy.out,type="response")
predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[log2prob.test > 0.5] = 2
}
if (bestmodel == 6)  {
log5fit.train = glm(HD ~ ., data= trainxy.out, family=binomial)
log5prob.test = predict(log5fit.train,testxy.out,type="response")
predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[log5prob.test > 0.5] = 2
}
#relabel as original values, not factor levels
predictvalid = predictvalid-1  # now a vector of predicted 0-1 values for HD in validation set
#assessment
CV.valid = sum(testxy.out$HD!=predictvalid)/nvalid
p.valid = 1-CV.valid
p.valid
---
title: "Midterm"
getwd()
